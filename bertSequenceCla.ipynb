{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertSequenceCla.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuP1LhnR0P3vMYXKW/uN3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aviva-Chen/bertForClassification_/blob/main/bertSequenceCla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMZtDqz9Rx2d",
        "outputId": "ff7d220a-4fe0-4740-eadf-59cbcdc72218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/bertFolder\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path='/content/gdrive/MyDrive/bertFolder'\n",
        "os.chdir(path)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "y3zWnukdTYBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_data=[]\n",
        "labels=[]\n",
        "\n",
        "df = pd.read_excel(\"/content/gdrive/MyDrive/bertFolder/wholeDataset.xlsx\", names=['title', 'label'])\n",
        "print('finish loading')\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df1 = shuffle(df)\n",
        "\n",
        "\n",
        "train_data0=list(df1['title'])\n",
        "\n",
        "labels=list(df1['label'])\n",
        "for title in train_data0:\n",
        "    train_data.append(str(title))\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT1p95Y-RsV6",
        "outputId": "78494453-d957-45f4-8c69-58f4a5129edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish loading\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import nn, optim\n",
        "from transformers import BertModel, BertTokenizer,DistilBertTokenizer, BertForSequenceClassification, BertConfig\n",
        "#将数据转化为data_loader形式\n",
        "tokenizer=DistilBertTokenizer.from_pretrained('distilbert-base-uncased')  \n",
        "\n",
        "max_length=32\n",
        "traindata_tokened = tokenizer(train_data,padding=True,truncation=True,max_length=max_length,return_tensors='pt')\n",
        "labels=torch.tensor(labels)\n",
        "\n",
        "#encoding data\n",
        "from torch.utils.data import TensorDataset,Dataset,DataLoader,random_split, RandomSampler, SequentialSampler\n",
        "class DataToDataset(Dataset):\n",
        "    def __new__(cls,encoding,labels):\n",
        "        return Dataset.__new__(cls)\n",
        "    def __init__(self,encoding,labels):\n",
        "        self.encoding=encoding\n",
        "        self.labels=labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self,index):\n",
        "        return self.encoding['input_ids'][index],self.encoding['attention_mask'][index],self.labels[index]\n",
        "train_dataset = DataToDataset(traindata_tokened,labels)\n",
        "\n",
        "#封装数据,labels是训练数据的标签，targets是测试数据的标签\n",
        "train_size = int(0.95 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "BATCH_SIZE=64\n",
        "train_loader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset,batch_size = BATCH_SIZE,shuffle=True)"
      ],
      "metadata": {
        "id": "6IBTYcEWwjQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#建立模型\n",
        "from transformers import DistilBertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "#model = BertForSequenceClassification.from_pretrained(\"Bert-base-uncased\",num_labels = 2, output_attentions = False,output_hidden_states = False)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", output_attentions = False,output_hidden_states = False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "yhOhfmRNtpb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "RVrdjctqseia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    \n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKY-uxJRJgwF",
        "outputId": "827f0604-4e1d-40eb-af90-1876ab4029b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5,eps = 1e-8)\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs=3\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0,num_training_steps = total_steps)\n",
        "\n",
        "training_stats=[]\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "total_t0=time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
        "        \n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        #outputs= model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n",
        "        outputs= model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)\n",
        "    \n",
        "        #print(outputs)\n",
        "        loss=outputs[0]\n",
        "        logits=outputs[1]\n",
        "       \n",
        "        train_loss_set.append(loss.item())\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in val_loader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)\n",
        "            #outputs = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n",
        "            loss=outputs[0]\n",
        "            logits=outputs[1]\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(val_loader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"----\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
        "\n"
      ],
      "metadata": {
        "id": "BIj5QuF3wmnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/bertFolder')\n",
        "\n",
        "#保存模型\n",
        "torch.save(model,'/content/gdrive/MyDrive/bertFolder/model2.pt')\n"
      ],
      "metadata": {
        "id": "3lz1rEnEOxBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#总结训练过程\n",
        "pd.set_option('precision',2)\n",
        "df_stats=pd.DataFrame(data=training_stats)\n",
        "df_stats=df_stats.set_index('epoch')\n",
        "print(df_stats)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "839l9LolOU5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#测试集性能\n",
        "import pandas as pd\n",
        "\n",
        "test_df=pd.read_excel('/content/gdrive/MyDrive/bertFolder/testSet.xlsx',sheet_name='Sheet3',names=['title given by machine','label'])\n",
        "test_data0=list(test_df['title given by machine'])\n",
        "\n",
        "sentences=[str(i) for i in test_data0]\n",
        "labels=list(test_df['label'])\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    print(sent)\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,  # Sentence to encode.\n",
        "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "        max_length=64,  # Pad & truncate all sentences.\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,  # Construct attn. masks.\n",
        "        return_tensors='pt',  # Return pytorch tensors.\n",
        "    )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "total_test_accuracy=0\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids, token_type_ids=None,attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "  total_test_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "  avg_test_accuracy = total_test_accuracy / len(prediction_dataloader)\n",
        "  print(\"  Accuracy: {0:.3f}\".format(avg_test_accuracy))\n",
        "\n",
        "\n",
        "print('DONE.')\n",
        "print('Positive samples: %d of %d (%.2f%%)'%(labels.sum(),len(labels),(labels.sum()/len(labels)*100.0)))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "    matthews_set.append(matthews)\n",
        "\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Combine the results across all batches.\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(classification_report(flat_predictions,flat_true_labels,digits=3))\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "aESaxbxwBVsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VLgVhQY8krSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21019cdb-c490-4c33-ace7-833182706918"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Aviva-Chen/bertForClassification.git"
      ],
      "metadata": {
        "id": "WIci6pAzYCGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b38342-d289-42a9-f9e1-12bffc9b1ac1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bertForClassification'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    }
  ]
}